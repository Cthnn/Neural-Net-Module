{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Machine Learning Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzRMNvc0_7wY"
      },
      "source": [
        "# Machine Learning With the MNIST HandwritingDataset\n",
        "---\n",
        "Today we're going to do some machine learning in python. For those that would like to use what you learn here and go deeper into machine learning, the frameworks and libraries we will be using are\n",
        "\n",
        "\n",
        "1.   numpy\n",
        "2.   scikit-learn\n",
        "3.   matplotlib\n",
        "4.   pytorch\n",
        "5.   opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvTcS3i6_2iU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0HF62NUBF3T"
      },
      "source": [
        "# Next we're going to load our data\n",
        "---\n",
        "We can simply load the data from pytorch's datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vcOFkNB_7Z_"
      },
      "source": [
        "# Load our datasets from pytorch\n",
        "train = torchvision.datasets.MNIST(root='/imgs',train=True,download=True)\n",
        "test = torchvision.datasets.MNIST(root='/imgs',train=False,download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvh1RI-xFII2"
      },
      "source": [
        "# Initialize our empty lists to add our data to them\n",
        "x_train, y_train,x_test,y_test = [],[],[],[]\n",
        "# Go through the training set and add the data to x_train and labels to y_train.\n",
        "# Also normalize the data (may not be necessary in this case)\n",
        "for data in train:\n",
        "  y_train.append(data[1])\n",
        "  img = data[0]\n",
        "  img = ((img-np.mean(img))/np.std(img))\n",
        "  x_train.append(img)\n",
        "# Go through the test set and add the data to x_test and labels to y_test.\n",
        "# Also normalize the data (may not be necessary in this case)\n",
        "for data in test:\n",
        "  y_test.append(data[1])\n",
        "  img = data[0]\n",
        "  img = ((img-np.mean(img))/np.std(img))\n",
        "  x_test.append(img)\n",
        "\n",
        "#Randomly display an image from the training set just to visualize our data\n",
        "i = np.random.randint(0,len(x_train))\n",
        "print(y_train[i])\n",
        "plt.figure\n",
        "plt.imshow(x_train[i], 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi5OP3bFYTci"
      },
      "source": [
        "# Data Preparation\n",
        "---\n",
        "We're going to preprocess our data for our machine learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbU2dnUu4k_O"
      },
      "source": [
        "# Apply normalization on our data to zero center it\n",
        "x_train = x_train-np.mean(x_train)\n",
        "\n",
        "# Define our model's parameters (784 in features, 10 out features, 400 neurons in hidden layer)\n",
        "imgSize = (28,28)\n",
        "batchSize = 100\n",
        "inFeatures,outFeatures,hidden = imgSize[0]*imgSize[1],len(set(y_train)),400 \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR8BTxqQ7Stn"
      },
      "source": [
        "# Make batches of data and labels\n",
        "def make_batches(in_data,in_labels,imgSize,batchSize=100,color= False,shuffle = False):\n",
        "\n",
        "  # If the image is in color, we'll have to account for the R,G,B, channels\n",
        "  channels = 1\n",
        "  if color:\n",
        "    channels = 3\n",
        "\n",
        "  # Mainly for train data, shuffles the data around\n",
        "  data,labels = in_data,in_labels\n",
        "  if shuffle:\n",
        "    shuffled = list(zip(in_data, in_labels))\n",
        "    random.shuffle(shuffled)\n",
        "    data, labels = zip(*shuffled)\n",
        "\n",
        "  # Create batches of tensors\n",
        "  batch_data = []\n",
        "  batch_labels = []\n",
        "  for i in range(int(len(data) / batchSize)):\n",
        "    minibatch_d = data[i*batchSize: (i+1)*batchSize]\n",
        "    minibatch_d = np.reshape(minibatch_d, (batchSize, 1,imgSize[0], imgSize[1]))\n",
        "    batch_data.append(torch.from_numpy(minibatch_d))\n",
        "    minibatch_l = labels[i*batchSize: (i+1)*batchSize]\n",
        "    batch_labels.append(torch.LongTensor(minibatch_l))\n",
        "  return zip(batch_data,batch_labels)\n",
        "\n",
        "#Call our function for making batches\n",
        "\n",
        "train_data = list(make_batches(x_train,y_train,imgSize,batchSize,color = False,shuffle=True))\n",
        "test_data = list(make_batches(x_test,y_test,imgSize,batchSize,))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0doEzz75Err"
      },
      "source": [
        "# Building Our Model\n",
        "\n",
        "---\n",
        "Our next step is to create our neural network, train the network on our data, and test it on our test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGFwfXls5D2K"
      },
      "source": [
        "# Create a Feed Forward NN\n",
        "class ANN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, out_size):\n",
        "        super(ANN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, out_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2_Tohqf5PvI"
      },
      "source": [
        "# Initialize our model, loss function, and optimizer function\n",
        "model = ANN(inFeatures,hidden,outFeatures).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
        "\n",
        "#Train for 100 epochs\n",
        "for epoch in range(100):\n",
        "  for i, data in enumerate(train_data, 0):\n",
        "    # Change the shape of our data to match the input shape of the model\n",
        "    inputs,labels = data\n",
        "    inputs = Variable(inputs.view(-1,28*28))\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward Propagation\n",
        "    out = model((inputs.float()).cuda())\n",
        "\n",
        "    loss = criterion(out.cuda(), labels.cuda())\n",
        "    # Backward Propagation\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX5IRWCMFvS7"
      },
      "source": [
        "# Results on the test set\n",
        "test_labels = []\n",
        "res = []\n",
        "for i, data in enumerate(test_data,0):\n",
        "  inputs, labels = data\n",
        "  inputs = Variable(inputs.view(-1,28*28))\n",
        "  labels = Variable(labels)\n",
        "  outputs = model((inputs.float()).cuda())\n",
        "  _,pred = torch.max(outputs, 1)\n",
        "  test_labels = test_labels + labels.tolist()\n",
        "  res = res + pred.tolist()\n",
        "\n",
        "print(accuracy_score(test_labels,res)*100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}